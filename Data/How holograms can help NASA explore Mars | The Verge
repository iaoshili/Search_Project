{"Main text":"Share on Facebook Tweet Share Pin Share\nNASA has gotten really good at successfully landing robots on Mars, but we're still decades away from getting humans there. Thanks to a new partnership with Microsoft, the space agency is about to bridge the gap between robot and human exploration by using immersive augmented reality.\nWindows Holographic and HoloLens made up one of the most exciting announcements at Microsoft\u2019s big event this week. During and after the event, the demonstrations ranged from using the augmented reality goggles to play a living room-sized version Minecraft to working with a CAD-like software. But the most audacious demo was of OnSight, a program developed for HoloLens by NASA\u2019s Ops Lab . It lets scientists explore a virtual Mars using data collected by the Curiosity rover. It's collaborative, too: scientists in different locations can join the session remotely, appearing in each other's HoloLens as humanoid avatars. Our own Tom Warren tried it out in Redmond and said it was jaw-dropping .\nOps Lab is in charge of building systems for controlling robots and spacecraft at NASA\u2019s Jet Propulsion. Some of their projects include controlling articulating arms , building immersive environments , and controlling robots like Robonaut 2 and Athlete using technology like the Oculus Rift and a Kinect sensor. The Ops Lab team is already integrating OnSight into the Curiosity team\u2019s software \u2014 so how did they get there?\nThe partnership began over five years ago. During the Project Natal days of Microsoft\u2019s Kinect, Ops Lab\u2019s project manager Jeff Norris was introduced to Kinect (and HoloLens) creator Alex Kipman. The two hit it off. \"Our teams started talking about how we could use technologies that were being developed in his incubation group to better control robots and spacecraft,\" Norris tells me.\nA partnership five years in the making\nNot long after that, Kipman showed Norris an early version of what would eventually become Windows Holographic and HoloLens. At that moment Norris says he knew there was potential, and they started figuring out how they could use it in space exploration. That collaboration resulted in a program that will expand the capabilities of the Curiosity team scientists.\nOnSight takes the data and images from the Curiosity rover and uses HoloLens to make a room appear to be the surface of Mars. Mission scientists will virtually step onto the surface and move around with an extra sense of perspective and presence not afforded by two-dimensional images, and that will improve the quality of conclusions drawn from things like shape and layout of geological features. HoloLens will also be aware of where a scientist's computer is, cutting it out of the virtual scene and letting a user control a mouse seamlessly between the desktop and the surface.\nCuriosity scientists will mostly interact with OnSight by using the global interactions built into Holographic. There are gesture and voice controls, and each scientist\u2019s avatar has a \"gaze ray\" that draws a line to what they\u2019re looking at, making it easier for other participants to follow along. Being able to use a computer while wearing HoloLens \u2014 another part that impressed us in Redmond \u2014 will let scientists take advantage of the raw data available in MSLICE, a program that provides the raw data from Curiosity that has been fully integrated with OnSight.\nThe Ops Lab team views presence \u2014 whether real or virtual \u2014 as a critical tool for the explorer. \"What a geologist is doing when they\u2019re looking at a scene is they\u2019re trying to understand a story that this environment has to tell them,\" Norris says. \"One of the chapters of that story is the shape of the environment \u2014 the way that the rocks are worn, the way that they form lines and curves. That information is one of the ways that they divine what\u2019s happening.\"\nHead-mounted displays yielded more accurate results\nHe cites a study the Ops Lab team performed over a year ago: 17 rover scientists were given standard images of a Martian scene provided by MSLICE. They then viewed the same scene through a head-mounted display. In both cases, the participants were asked to draw a map of the shape of the environment and flag the location of certain points of interest. The scientists\u2019 estimation of distances was more than twice as accurate while wearing the head-mounted displays, and their estimation of the angles of objects was more than three times as accurate.\nMore surprisingly, Norris says the scientists were accomplishing this increased accuracy without any basic VR or AR training \u2014 only one of the people in the admittedly few person study had ever even worn a head-mounted display before. \"That\u2019s what really put the wind in our sails to go further with this,\" Norris says.\nWhile the Curiosity team has already been able to do great work with two- and three-dimensional images of the surface, OnSight is the next evolved step in how they analyze the data. It\u2019s a better option than viewing a 3D-model (or stereoscopic images) because of the power of proprioception, or the body\u2019s sense of self. \"Your body, as you\u2019re walking around in a place on Earth, knows where it is. And your eyes are presenting to your brain images of what you see at that position,\" says Norris. The integration of those things is essential to building a mental model of your environment, and it\u2019s why the Ops Lab team is so excited about the work they\u2019ve done with OnSight.\nOps Lab was already working on immersive interaction, using an Oculus Rift. But the Rift presented its limitations for NASA, like its need for wires and how it closes users off from their surroundings. HoloLens relieves both of those problems, so the Ops Lab team started an  intense development period about a year ago to create OnSight \u2014 so intense that a portion of Norris\u2019s team actually moved to Redmond to live and work shoulder to shoulder with the HoloLens team.\nUltimately, the goal is to test OnSight in actual operations later this year, though Norris couldn\u2019t say when. But Curiosity scientists already professed excitement in a video released this week by JPL. Geologist Fred Calef says not only is OnSight \"like teleportation,\" but it will also save time. Katie Stack Morgan says the enhanced visualization will help the team make better decisions about operating the rover in general \u2014 an important issue considering the problems the team has had with things like wheel degradation.\nThat doesn\u2019t mean OnSight is close to being a finished product. \"There\u2019s a lot of work to do,\" Norris says. \"It\u2019s no trivial undertaking to bring a new capability into mission operations.\" And beyond Curiosity, nothing is set in stone \u2014 but Norris says there is vision to take this past Mars to other planets in the solar system. \"This is a new tool in the toolbox of explorers.\"\n","Title":"How holograms can help NASA explore Mars | The Verge","Tags":["microsoft","report","science","tech"]}