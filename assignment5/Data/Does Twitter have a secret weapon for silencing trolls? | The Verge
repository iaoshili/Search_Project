{"Main text":"Does Twitter have a secret weapon for silencing trolls?\nA British lawmaker complained of abuse. Suddenly, the abuse stopped.\nShare on Facebook Tweet Share Pin Share\nLuciana Berger, a member of British Parliament, has been receiving a stream of anti-Semitic abuse on Twitter. It only escalated after a man was jailed for tweeting her a picture with a Star of David superimposed on her forehead and the text \"Hitler was Right.\" But over the last few weeks, the abuse began to disappear. Her harassers hadn\u2019t gone away, and Twitter wasn't removing abusive tweets after the fact, as it sometimes does, or suspending accounts as reports came in. Instead, the abuse was being blocked by what seems to be an entirely new anti-abuse filter.\nFor a while, at least, Berger didn\u2019t receive any tweets containing anti-Semitic slurs, including relatively innocuous words like \"rat.\" If an account attempted to @-mention her in a tweet containing certain slurs, it would receive an error message, and the tweet would not be allowed to send. Frustrated by their inability to tweet at Berger, the harassers began to find novel ways to defeat the filter, like using dashes between the letters of slurs, or pictures to evade the text filters. One white supremacist site documented various ways to evade Twitter\u2019s censorship, urging others to \"keep this rolling, no matter what.\"\nthe harassers began to find novel ways to defeat the filter\nIn recent months, Twitter has come under fire for the proliferation of harassment on its platform\u2014in particular, gendered harassment. (According to the Pew Center, women online are more at risk from extreme forms of harassment like \"physical threats, stalking, and sexual abuse.\") Twitter first implemented the ability to report abuse in 2013, in response to the flood of harassment received by feminist activist Caroline Criado-Perez. The recent surge in harassment has again resulted in calls for Twitter to \"fix\" its harassment problem, whether by reducing anonymity , or by creating better blocking tools that could mass-block harassing accounts or pre-emptively block recently created accounts that tweet at you. ( The Blockbot , Block Together , and GG Autoblocker are all instances of third party attempts to achieve the latter.) Last week, the nonprofit Women, Action, & the Media announced a partnership with Twitter to specifically track and address gendered harassment.\nTwitter has come under fire for the proliferation of harassment\nWhile some may welcome the mechanism deployed against Berger\u2019s trolls as a step in the right direction, the move is troubling to free speech advocates. Many of the proposals to deal with online abuse clash with Twitter\u2019s once-vaunted stance as \" the free speech wing of the free speech party ,\" but this particular instance seems less like an attempt to navigate between free speech and user safety, and more like a case of exceptionalism for a politician whose abuse has made headlines in the United Kingdom. The filter, which Twitter has not discussed publicly, does not appear as if it's intended to be a universal fix for harassment that is experienced by less-important users on the platform, such as the women targeted by Gamergate .\nPrior to the filter being activated, Luciana Berger and her fellow MP, John Mann, had announced plans to visit Twitter\u2019s European Headquarters , to talk to higher-ups about the abuse. Parliament is currently discussing more punitive laws against online trolling , including a demand from Mann for a way to ban miscreants from \"specific parts of social media or, if necessary, to the Internet as a whole.\"\nPrior to the filter being activated, Luciana Berger had announced plans to visit Twitter's headquarters\nIn a letter to Berger that is quoted in part here , Twitter\u2019s head of global safety outreach framed efforts over the past year as including architectural solutions to harassment. \"Our strategy has been to create multiple layers of defense, involving both technical infrastructure and human review, because abusive users often are highly motivated and creative about subverting anti-abuse mechanisms.\" The letter goes on to describe known mechanisms, like the use of \"signals and reports from Twitter users to prioritize the review of abusive content,\" and hitherto unknown mechanisms like \"mandatory phone number verification for accounts that indicate engagement in abusive activity.\" However, the letter says nothing about a selective filter for specific words. To achieve that result, the company appears to have used an entirely new tool outside of its usual arsenal.\nA source familiar with the incident told us, \"Things were used that were definitely abnormal.\"\nA former engineer at Twitter, speaking on the condition of anonymity, agreed, saying, \"There\u2019s no system expressly designed to censor communication between individuals. \u2026 It\u2019s not normal, what they\u2019re doing.\"\nHe and another former Twitter employee speculated that the censorship might have been repurposed from anti-spam tools\u2014in particular, BotMaker, which is described here in an engineering blog post by Twitter . BotMaker can, according to Twitter \"deny any Tweets\" that match certain conditions. A tweet that runs afoul of BotMaker will simply be prevented from being sent out\u2014an error message will pop up instead. The system is, according to a source, \"really open-ended\" and is frequently edited by contractors under wide-ranging conditions in order to effectively fight spam.\nWhen asked whether a new tool had been used, or BotMaker repurposed, a Twitter spokesperson replied: \"We regularly refine and review our spam tools to identify serial accounts and reduce targeted abuse. Individual users and coordinated campaigns sometimes report abusive content as spam and accounts may be flagged mistakenly in those situations.\"\n\"Things were used that were definitely abnormal\"\nIt\u2019s not clear whether this filter is still in place. (I attempted to test it with \"rat,\" the only word that I was willing to try to tweet, and my tweet did go through. The filter may have been removed, the word \"rat\" may have been removed from the blacklist, or the filter may have only been applied to recently created accounts).\nIt\u2019s hard to shed a tear for a few missing slurs, but the way they were censored is deeply alarming to free speech activists like Eva Galperin of the Electronic Frontier Foundation. \"Even white supremacists are entitled to free speech when it\u2019s not in violation of the terms of service. Just deciding you\u2019re going to censor someone\u2019s speech because you don\u2019t like the potential political ramifications for your company is deeply unethical. The big point here is that someone on the abuse team was worried about the ramifications for Twitter. That\u2019s the part that\u2019s particularly gross.\"\nWhat\u2019s worrisome to free speech advocacy groups like the EFF about this incident is how quietly it happened. Others may see the bigger problem being the fact that it appears to have been done for the benefit of a single, high-profile user, rather than to fix Twitter\u2019s larger harassment issues. The selective censorship doesn\u2019t seem to reflect a change in Twitter abuse policies or how they handle abuse directed at the average user; aside from a vague public statement by Twitter that elides the specific details of the unprecedented move, and a few, mostly-unread complaints by white supremacists, the entire thing could have gone unnoticed.\nThe way they were censored is deeply alarming to free speech activists\nEva Galperin thinks incidents like these could be put in check by transparency reports documenting the application of the terms of services, similar to how Twitter already puts out transparency reports for government requests and DMCA notices . But while a transparency report might offer users better information as to how and why their tweets are removed, some still worry about the free-speech ramifications of what transpired. One source familiar with the matter said that the tools Twitter is testing \"are extremely aggressive and could be preventing political speech down the road.\" He added, \"are these systems going to be used whenever politicians are upset about something?\"\n","Title":"Does Twitter have a secret weapon for silencing trolls? | The Verge","Tags":["culture","report","tech"]}